\documentclass[12pt]{article}
\usepackage{hyperref, fancyhdr, setspace, array, keycommand, lastpage, xcolor}
\usepackage{enumerate, enumitem}
\usepackage{multiaudience, environ}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{mathtools}
\usepackage[margin=1 in]{geometry}
\allowdisplaybreaks
\hypersetup{
	linktoc=all,
	linkcolor=black,
}
\author{Allan Wang} 
\date{Last updated: \today}
\title{MATH 223: Linear Algebra}
\pagestyle{fancy}
\lhead{MATH 223}
\chead{\leftmark}
\rhead{Allan Wang}
\cfoot{Page \thepage \ of \pageref{LastPage}}

\SetNewAudience{compact}
\SetNewAudience{full}
\def\CurrentAudience{full}

\setlength{\parindent}{0pt}

\newcommand{\tab}[1]{\hspace{.2\textwidth}\rlap{#1}}

\newcommand{\mathcomment}[0]{\quad\color{blue}} 

\newcommand{\comment}[1]{}

\renewcommand{\v}[1]{\overrightarrow{#1}}
\newcommand{\vectorset}[1]{\{\v{#1_1}, \v{#1_2}, ..., \v{#1_k}\}}
\newcommand{\vectorseq}[2]{\v{#1_1}, \v{#1_2}, ..., \v{#1_#2}}
\newcommand{\vectorseqtwo}[2]{#1_1\v{#2_1} + #1_2\v{#2_2} + ... + #1_k\v{#2_k}}
\newcommand\m[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand\mm[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\real}[0]{\mathbb{R}}
\newcommand{\complex}[0]{\mathbb{C}}
\renewcommand{\natural}[0]{\mathbb{N}}

\newenvironment{block}[1][Label]{\underline{#1}\par}{}
\newenvironment{proof}{\block[Proof]}{\endblock}
\newenvironment{proposition}{\block[Proposition]}{\endblock}
\newenvironment{lemma}{\block[Lemma]}{\endblock}
\newenvironment{theorem}{\block[Theorem]}{\endblock}
\newenvironment{remark}{\block[Remark]}{\endblock}
\newenvironment{definition}{\block[Definition]}{\endblock}

\newkeycommand{\vv}[base=u, end=n] {
	\v{\commandkey{base}_1}, \v{\commandkey{base}_2}, ..., \v{\commandkey{base}_{\commandkey{end}}}
}

\newkeycommand{\vsum}[co=, base=u, end=n] {
	\commandkey{co}_1\v{\commandkey{base}_1} + \commandkey{co}_2 \v{\commandkey{base}_2} + ... + \commandkey{co}_{\commandkey{end}} \v{\commandkey{base}_{\commandkey{end}}}	
}

% TODO customize style
\newcommand{\uu}[1]{\underbracket{#1}}

\newcommand{\todo}[0]{\text{\textcolor{red}{\textbackslash\textbackslash TODO \ }}}

\newcommand{\st}[0]{\text{ s.t. }}

% \NewEnviron{examples}{
% 	\begin{shownto}{-,compact}
% 		\underline{Examples}
% 		\begin{enumerate}
% 			\BODY
% 		\end{enumerate}
% 	\end{shownto}
% }
% \newenvironment{examples}{\underline{Examples}\enumerate}{\endenumerate\divider}
\newenvironment{examples}{\shownto{-,compact}\underline{Examples}\enumerate}{\endenumerate\divider\endshownto}

\newenvironment{example}{\shownto{-,compact}\underline{Example}~\\}{\divider\endshownto}

\newenvironment{test}{\shownto{-,compact}\enumerate}{\endenumerate\endshownto}

\newcommand{\bb}[1]{\left\{#1\right\}}
\newcommand{\bbb}[1]{\left[#1\right]}
\newcommand{\pp}[1]{\left(#1\right)}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\ang}[1]{\langle#1\rangle}

\newcommand{\divider}[0]{\par\textcolor{lightgray}{\rule{\textwidth}{0.1pt}}}

\newkeycommand{\ssum}[sub=i=1, sup=n] {
	\sum_{\commandkey{sub}}^{\commandkey{sup}}	
}

\newcommand{\sspan}[1]{\text{span}\bb{#1}}

\newenvironment{eqn}{\equation\alignedat{3}}{\endalignedat\endequation}

\setlist[enumerate]{itemsep=0mm}
\setlist[itemize]{itemsep=0mm}
\begin{document}
	
	\onehalfspacing
	\maketitle
	\tableofcontents
	\pagebreak
	\section{2018/01/9}
	
	
	\section{2018/01/11}
	
	$v \subseteq \real^n$ is a subspace of $\real^n$ if \\
	
	\begin{tabular}{@{}l l l}
		1. & $\vec{O} \in V$ & ie $V$ is non empty \\
		2. & $\vec{u} + \vec{v} \in V$ & whenever $\vec{u} \in V + \vec{\alpha} \in V$ \\
		3. & $\alpha \vec{u} \in V$ & whenever $\vec{u} \in V, \vec{\alpha} \in \real$	
	\end{tabular} \\
	
	A subspace $V$ of $\real$ has a basis
	
	ie a family $\bb{\vv[end=k]}$ of vectors in $V$ such that $\bb{\vv[end=k]}$ is a spanning set of $V$
	
	A spanning set of $V$ is a set such that every vector in $V$ is a linear combination of that set
	
	ie whenever $\vsum[co=\alpha,end=k] = 0$
	
	if $A\alpha = 0$, rank of $A$ is $k (\le n)$, where $k =$ dimension of $V$
	
	\begin{examples}
		\item $E = \bb{\v{u} = \m{t \\ 2t + s \\ 1}, t \in \real, s \in \real} \subseteq R^3$
		* $E$ is not a subspace of $R^3$ as the 0 matrix is not included
		\item $F = \bb{\v{u} = \m{t + s \\ 2t + s' \\ 1}, t, s' \in \real} \subseteq R^3$ \\
		$\v{u} \in F \Rightarrow \m{t + s \\ 2t = s' \\ 0} = t\m{1 \\ 2 \\ 0} + s'\m{1 \\ -1 \\ 0}$ \\
		$F =$ span $\bb{\m{1 \\ 2 \\ 0}, \m{1 \\ -1 \\ 0}}$ (linearly independent)
		\item let $A = \m{1, 1 \\ 2, -1 \\ 0, 0} \rightarrow \m{1, 0 \\ 0, 1 \\ 0, 0}$ \\
		Rank$(A) = 2$: therefore $\bb{\m{1, 1 \\ 2, -1 \\ 0, 0} \m{1, 0 \\ 0, 1 \\ 0, 0}}$ is linearly independent.
	\end{examples}
	
	\section{2018/01/16}
	
	\subsection{Diagonalization}
	
	\(T: R^2 \rightarrow R^2\)
	
	projection onto the line
	
	\(A = \frac{1}{2} \m{1 & -1 \\ -1 & 1}\)
	
	x + y = 0
	
	A is diagonalizable, ie \(A + P \cdot D \cdot P^{-1}\)
	
	where \(D = \m{1 & 0 \\ 0 & 0}, P = \m{1 & 1 \\ -1 & 1}\)
	
	Let \(\v{u_1} = \m{1 \\ -1}\) and \(\v{v_1} = \m{1 \\ 1}\)
	
	The canonical basis of \(\real^2\) is \(B = \bb{\m{1 \\ 0} = \v{i}, \m{0 \\ 1} = \v{j}}\)
	
	Note that \(B_1 = \bb{\v{u_1}, \v{v_1}}\) is also a basis of \(\real^2\)
	
	A is the standard matrix of \(T\), it is in fact the matrix of \(T\) through the canonical basis of \(B\)
	
	a vector \(\v{u} \in \v{\real^2}\) has coordinates \(\m{x \\ y}\) with respect to \(B\).
	
	The coordinates of \(T(\v{u})\) with respect to \(B\) is \(A \m{x \\ y} = A\pp{P \m{x_1 \\ y_1}}\) 
	
	Let \(\m{x_1 \\ y_1}\) be the coordinates of \(\v{u}\) with respect to \(B_1\)
	
	\(\v{us} = \v{x_i} + \v{y_j} = x_1 \v{u_1} + y_1 \v{v_1}\) \\
	\(\Rightarrow \m{x \\ y} = P \m{x_1 \\ y_1}\)
	
	\(P^{-1}AP \m{x_1 \\ y_1} = D \m{x_1 \\ y_1} = \m{x_1 \\ 0}\)
	
	\(D\) is the matrix of the linear transformation \(T\) through the basis \(B_1\)
	
	\divider
	
	\subsection{Vector Spaces}
	
	Let \(K\) be a field \(\pp{K = \real, K = \complex}\)
	Let \(V\) be a nonempty set
	\(V\) is equipped with 2 operations
	
	\begin{tabular}{@{} l l}
		Additions	& if \(\v{u} \in \v{v}, \v{v} \in V\), then sum \(\v{u} + \v{v}\) is defined \\
		Scalar Multiplication & if \(\v{u} \in V, \alpha \in \real, \alpha \v{u}\) is defined
	\end{tabular}
	
	\(V\) is called a vector space (over \(K\)) if the following properties hold:
	
	\begin{enumerate}[label=\(A_{\arabic*}\)]
		\item whenever \(\v{u}, \v{v} \in V, \v{u} + \v{v} \in V\)
		\item whenever \(\v{u}, \v{v} \in V, \v{u} + \v{v} = \v{v} + \v{u}\)
		\item whenever \(\v{u}, \v{v}, \v{w} \in V, \pp{\v{u} + \v{v}} + \v{w} = \v{u} + \pp{\v{v} + \v{w}}\)
		\item there exists a special vector in \(V\) called the zero vector, denoted by \(\v{0}\) such that whenever \(\v{u} \in V\), \(\v{u} + \v{0} = \v{0} + \v{u} = \v{u}\)
		\item Given \(\v{u} \in V\), there exists \(\v{w} \in V\) such that \(\v{u} + \v{w} = \v{w} + \v{u} = \v{0}\) \\
		\(\v{w}\) is denoted by \(-\v{u}\)
	\end{enumerate}
	
	\divider
	
	\begin{enumerate}[label=\(S_{\arabic*}\)]
		\item \(\forall \alpha \in K, \forall \v{u} \in V, \alpha vec{u} \in V\)
		\item \(1 \cdot \v{u} = \v{u}, 1 \in K(K = \real), \v{u} \in V\)
		\item whenever \(\alpha, \beta \in K, \v{u} \in V, \alpha \pp{\beta \v{u}} = \pp{\alpha \beta} \v{u}\)
		\item whenever \(\alpha, \beta \in K, \v{u} \in V, \pp{\alpha + \beta}\v{u} = \alpha \v{u} + \beta \v{u}\)
		\item whenever \(\alpha \in K, \v{u}, \v{v} \in V\), \(\alpha \pp{\v{u} + \v{v}} = \alpha \v{u} + \alpha \v{v}\)s
	\end{enumerate}
	
	\divider
	
	\begin{examples}
		\item \(V = \real^n\) is a vector space over \(K = \real\)
		\item let \(M_{p \times q}\) be the set of all \(p \times q\) matrices \\
		\(M_{p \times q}\) is a vector space over \(\real\)
		\item Let \(P\) be the set of all polynomials over \(\real\) \\
		\(P_1, P_2 \in P\), \(\pp{P_1 + P_2}(x) = P_1(x) + P_2(x) \ \forall x \in \real\) \\
		If \(\alpha \in \real \in K, \pp{\alpha P}(x) = \alpha P(x) \ \forall x \in \real\)
		\item Let \(0\) be the function such that \(0(x) = 0 \ \forall x\) 
	\end{examples}
	
	\section{2018/01/18}
	
	\subsection{Vector Spaces}
	
	Examples \\
	Let $D$ be a subset of $\real$ ($D$ can be an interval for example) \\
	Let $F(D)$ be the set of all real valued functions defined on $D$ \\
	For $f, g \in F(D)$, $\alpha, \beta \in \real$, $0 : D \rightarrow \real$
	
	\begin{itemize}
		\item $f + g : D \rightarrow \real$
		\item $(f + g)(x) = f(x) + g(x)$
		\item $(\alpha f)(x) = \alpha \cdot f(x)$
		\item $f + g = g + f$
		\item $(f + g) + h = f + (g + h)$
		\item $0(x) = 0$
		\item $f + 0 = f$
		\item $f + (-f) = 0$
		\item $1 \cdot f = f$
		\item $(\alpha + \beta) f(x) = \alpha f(x) + \beta f(x) = (\alpha f + \beta f)(x)$
	\end{itemize}
	
	Note that if we set $D = \natural$
	
	$F(\natural) =$ set of all real-valued sequences
	
	\subsection{Proposition}
	
	Let $(V, +, \cdot)$ be a vector space over $K$
	
	
	\begin{enumerate}
		\item The zero vector $\v{0}$ in $V$ is unique
		\item Given $\v{u} \in V$, the vector $\v{-u}$ is unique
		\item If $\alpha \v{u} = 0$ then $\alpha = 0$ or $\v{u} = \v{0}$
		\item $\v{-u} = (-1) \v{u}$
	\end{enumerate}
	
	\begin{proof}
		\begin{enumerate}
			\item Let $\v{0_1}$ and $\v{0_2}$ be two vectors such that
			
			\begin{equation}
			\begin{cases}
			\v{u} + \v{0_1} = \v{0_1} + \v{u} = \v{u} \quad \forall \v{u} \\
			\v{u} + \v{0_2} = \v{0_2} + \v{u} = \v{u} \quad \forall \v{u}
			\end{cases}
			\end{equation}
			
			It follows that \\
			$\v{0_1} = \v{0_1} + \v{0_2} = \v{0_2}$
			
			\item Let $\v{u} \in V$ and let $\v{w_1}$ and $\v{w_2}$ be two vectors such that \\
			$\v{u} + \v{w_1} = \v{0}$ \\
			$\v{u} + \v{w_2} = \v{0}$
			
			\begin{eqn}
				\v{u} + \v{w_1} &= \v{0} &\\
				\v{w_2} + (\v{u} + \v{w_1}) &= \v{w_2} + \v{0} &\\
				(\v{w_2} + \v{u}) + \v{w_1} &= \v{w_2} & \mathcomment \text{associativity}\\
				0 + \v{w_1} &= \v{w_2} &\\
				\v{w_1} &= \v{w_2} &
			\end{eqn}
			
			\item Suppose $\alpha \v{u} = 0$ 
			If $\alpha \ne 0$ \\
			
			\begin{eqn}
				\frac{1}{\alpha} \in K \quad K = \real \\
				\frac{1}{\alpha} (\alpha \v{u}) = \frac{1}{\alpha} \v{0} = \v{0} \\
				(\frac{1}{\alpha} \alpha) \v{u} = \v{0} \text{\quad ie} 1 \cdot \v{u} = \v{u} = 0
			\end{eqn}
			
			\item $-\v{u} = (-1) \v{u}$
			
			\begin{eqn}
				&& 1 + (-1) &= 0 \\
				&& (1 + (-1)) \v{u} &= 0 \v{u} = \v{u} \\
				&& 1 \v{u} + (-1) \v{u} &= \v{0} \\
				&& \v{u} + (-1) \v{u} &= \v{0} \\
				\therefore && (-1) \v{u} &= \v{-u}
			\end{eqn}
			
		\end{enumerate}
	\end{proof}
	
	\subsection{Subspaces}
	
	Let $(V, + \cdot)$ be a vector space over $K$ \\
	Let $E$ be a subset of $V (E \subseteq V)$ \\
	$(E, + \cdot)$ is called a subspace of $(V, +, \cdot)$ \\
	if $(E, +, \cdot)$ is a vector space over $K$.
	
	\begin{proposition}
		$E$ is a subspace of $V$ if the following properties hold:
		
		\begin{enumerate}
			\item $\v{0} \in E$ 
			\item Whenever $\v{u}, \v{v} \in E \qquad \v{u} + \v{v} \in E$
			\item Whenever $\v{u} \in E, \alpha \in K \qquad \alpha \v{u} \in E$
		\end{enumerate}
	\end{proposition}
	
	Notice that $E \subseteq V$ is a subspace of $V$ iff $E$ is nonempty and $\alpha \v{u} + \beta \v{v} \in E$ whenever $\v{u}, \v{v} \in E, \alpha, \beta \in K$
	
	\begin{examples}
		\item Let $C([0, 1])$ be the set of all continuous functions on $[0, 1]$ \\
		$C([0, 1]) \subseteq F([0, 1])  \leftarrow \text{vector space}$ \\
		The function $f: [0, 1] \rightarrow \real$ \\
		$f \in C([0, 1]) \text{(nonemptiness)}$ \\
		If $f$ and $g$ are continuous on $[0, 1]$, so if $f + g$, as well as $\alpha f \ \forall \alpha$ \\
		$C[0, 1]$ is a subspace of $F([0, 1])$
		
		\item Let $E = \bb{A \in M_{2 \times 2} \mid A = A^T}$ \\
		Note that $I_2 = \mm{1 & 0 \\ 0 & 1} \in E$ \\
		whenever $A, B \in E$, $(A + B)^T = A^T + B^T = A + B$ \\
		$A + B \in E$ \\
		Also $(\alpha A)^T = \alpha A^T = \alpha A$ \\
		ie $\alpha A \in E$ \\
		$E$ is a subspace of $M_{2 \times 2}$
	\end{examples}
	
	\section{2018/01/23}
	
	\subsection{Subspaces}
	
	\begin{examples}
		\item Let $E = \bb{p = P_3, \text{ such that } p(1) = 2}$ \\
		$E$ is a nonempty subset of $P_3 (p(x) = 2x \in E)$. But $E$ is neither stable under addition nor stable under scalar multiplication. \\\\
		Ex $p_1(x) = 2x \in E$, but $(4p_1)(x) = 8x \notin E$. \\
		$\therefore E$ is not a subspace 
		
		\item Let $E = \bb{p \in P_3 \mid p(0) \ge 0}$ \\
		The zero polynomial $(0) \in E$ \\
		let $p_1 \in E, p_2 \in E, (p_1 + _2)(0) = p_1(0) + p_2(0) \ge 0$ \\
		$p1 + p_2 \in E$ \\
		However, $E$ is not stable under scalar multiplication. \\
		Ex $p(x) = x + 1 \in E \leftarrow p(0) = 1 \ge 0$ \\
		if $\alpha < 0$, then $\alpha p(0) = \alpha < 0 \rightarrow \alpha p \notin E$
		
		\item If A is a $n \times m$ matrix \\
		$\text{Null}(A) = \bb{x \in \real^m \mid AX = 0}$ \\
		$\text{Null}(A)$ is a subspace of $\real^m$ \\
		\begin{proof}
			$X = 0 \in \text{Null}(A) \text{ since } A0 = 0$
			Let $X_1, X_2 \in \text{Null}(A)$ \\
			$A(X_1 + X_2) = AX_1 + AX_2 = 0 + 0 = 0$ \\
			If $X \in \text{Null}(A), \alpha \in \real$ \\
			$\alpha X \in \text{Null}(A)$ bc \\
			$A(\alpha X) = \alpha (AX) = \alpha 0 = 0$
		\end{proof}
	\end{examples}
	
	Let $(V, +, \cdot)$ be a vector space on $\real$. \\
	Let $\v{u_1}, \v{u_2}, ..., \v{u_n}$ be $n$ vector in $V$ 
	
	\begin{proposition}
		The subset $E \subseteq V$ of all linear combinations $(lc)$ of $\v{u_1}, \v{u_2}, ..., \v{u_n}$ is a subspace of $V$, and is denoted \\
		$E = \sspan{\v{u_1}, \v{u_2}, ..., \v{u_n}}$
		
		\begin{proof}
			\begin{enumerate}
				\item $\v{0} \in E$ bc $\v{0} = 0 \v{u_1} + 0 \v{u_2} + ... + 0 \v{u_n}$
				\item $E$ is stable under addition \\
				Let $\v{v} = \sum_{i=1}^n \alpha_i \v{u_i} \in E$ \\
				$\v{w} = \sum_{i=1}^n \beta_i \v{u_1} \in E$ \\
				$\v{v} + \v{w} = \sum_{i=1}^n (\alpha_i + \beta_i) \v{u_i} \in E$
				\item $E$ is stable under scalar multiplication \\
				$\v{u} =  \ssum \alpha_i \v{u_i} \in E$ and $\beta \in \real$ \\
				$\beta \v{u} = \beta(\ssum \alpha_i \v{u_i}) = \sum_{i=1}^n (\beta \alpha_i) \v{u_i} \in E$
			\end{enumerate}
		\end{proof}
	\end{proposition}
	
	\begin{examples}
		\item Let $A$ be a $n \times m$ matrix and $C_1, C_2, ..., C_m$ are the columns of $A$ (each column $\in \real^n$). \\
		$\sspan{C_1, C_2, ..., C_m}$ is a vector subspace of $\real^n$, called the column space of $A$ and denoted $\text{Col}(A) n$. \\
		Similarly, the row space of $A$ is $\text{Row}(A) = \text{Col}(A^T)$ is a subspace of $\real^m$.
		
		\item $E = P_3$ \\
		$p \in P_3), p(x) = ax^3 + bx^2 + cx + d$ \\
		$P_3 = \sspan{x^3, x^2, x, 1}$		
		
		\item $E = \bb{p \in P_3 \mid p(2) = 0}$ is a subspace of $P_3$ \\
		If $p \in E, p(x) = 0$ \\
		ie $p(x) = (x - 2)q(x)$ where $q(x) \in P_2$ \\
		$p(x) = (x - 2)(ax^2 + bx + c) = ax^2(x - 2) + bx(x - 2) + c(x - 2) \quad a, b, c \in \real$ \\
		$E = \sspan{x^2(x - 2), x(x - 2), x - 2}$ \\
		$p \in P_3, p(x) = sum_{k=0}^3 \frac{f^{(k)}(2)}{k!} (x - 2)^k$ \\
		if $p \in E, p(2) = 0$ \\
		\begin{eqn}
			p(x) &= \sum_{k=0}^3 \frac{p^{(k)}(2)}{k!} (x - 2)^k \\
			&= \frac{p^{(1)}(2)}{1!}(x - 2) + \frac{p^{(2)}(2)}{2!}(x-2)^2 + \frac{p^{(3)}(2)}{3!}(x-2)^3
		\end{eqn}
	\end{examples}
	
	\begin{proposition}
		Let $E$ be a subspace of $V$ \\
		Let $F_1 = \bb{\v{u_1}, \v{u_2}, ..., \v{u_n}}$ be a subset of vectors in $V$ \\
		$F_2 = \bb{\v{v_1}, \v{v_2}, ..., \v{v_n}}$ be a subset of vectors in $V$ \\
		$F_1$ and $F_2$ are both spanning sets of the same subspace $E$ of $V$ iff every vector in $F_1$ is a $lc$ of vectors in $F_2$ and every vector in $F_2$ is a $lc$ of vectors in $F_1$.
	\end{proposition}
	
	\section{2018/01/25}
	
	Wasn't there
	
	\section{2018/01/30}	
	
	\subsection{Linear Independence}
	
	\subsubsection{Properties}
	
	
	% PROPERTY sets should go to n, not k
	\begin{itemize}
		\item If a subset $\vv[end=k]$ of vectors in $V$ contains the zero vector $\pp{\v{u_i} = \v{0} \text{ for some } i}$, then it is linearly dependent
		
		\item If $F = \vectorset{u}$ is linearly independent, then any subset of $F$ is linearly dependent
		
		
		\todo update
		\item if $F = \vv$ is linearly independent, and $\bb{\v{u_1}, \v{u_2}, ..., \v{u_n}, \v{u_{n+1}}}$ is linearly independent, then $\v{u_{n+1}} \in \sspan{\v{u_1}, \v{u_2}, ..., \v{u_n}}$
		
		\begin{proof}
			\begin{enumerate}
				\item Without loss of generality, $\v{u_1} = \v{0}$ \\
				Note that $2 \v{u_1} + 0 \v{u_2} + 0 \v{u_3} + ... + 0 \v{u_n} = \v{0}$ \\
				As there is a nonzero coefficient, there must be linear dependence.
				
				\item Let $F = \vectorset{u}$ be linearly independent. \\
				Let $F_1$ be a subset of $F$ containing $k$ vectors, $k \le n$ \\
				%			WLOG, $F__1 = \bb{\v{u_1}, \v{u_2}, ..., \v{u_k}}$ \\
				$\sum_{i=1}^n \alpha_i \v{u_i} = \v{0} \Rightarrow \sum_{i=1}^k \alpha_i \v{u_i} + 0 \v{u_{i+1}} + 0 \v{u_{i+2}} + ... 0 \v{u_n} = \v{0}$
			\end{enumerate}
		\end{proof}
		
		Since $F$ is linearly independent, we must have $\alpha_1 = \alpha_2 = ... = \alpha_k = 0$
		
		\item Assume that $F = \vectorset{u}$ is linearly independent and $\bb{\v{u_1}, \v{u_2}, ..., \v{u_n}, \v{u_{n+1}}}$ is linearly dependent \\
		
		There exists a finite sequence $\alpha_1, \alpha_2, ..., \alpha_n, \alpha_{n+1}$, where not all values are zeroes, such that \\
		$\alpha_1 \v{u_1} + \alpha_2 \v{u_2} + ... + \alpha_n \v{u_n} + \alpha_{n+1} \v{u_{n+1}} = \v{0}(*)$ \\
		
		Claim $\alpha_{n+1} \ne 0$ \\
		Assume $\alpha_{n+1} = 0$ \\
		$\alpha_{n+1} = 0$ and $(*)$ yields \\
		$\alpha_1 \v{u_1} + \alpha_2 \v{u_2} + ... + \alpha_n \v{u_n} = \v{0}$ \\
		which implies $\alpha_1 = \alpha_2 = ... = \alpha_n = 0$ (since $F$ is linearly independent). That is a contraction, therefore $\alpha_{n+1} \ne 0$
		
		$(*)$ can be rewritten as $\alpha_{n+1} \v{u_{n+1}} = \alpha_1 \v{u_1} + \alpha_2 \v{u_2} + ... + \alpha_n \v{u_n} = \sum_{i=1}^n \alpha_i \v{u_i}$ \\
		$\v{u_{n+1}} = \sum_{i=1}^n -\pp{\frac{\alpha_i}{\alpha{n+1}}} \v{u_i}$ \qquad ie $\v{u_{n+1}} \in \sspan{\v{u_1}, \v{u_2}, ..., \v{u_n}}$
	\end{itemize}
	
	\begin{proposition}
		If $F = \vectorset{u}$ is linearly dependent, then one of the $\v{u_i}$ can be written as the linear combination of the others.
	\end{proposition}
	
	\underline{Basis} \\
	Let $V$ be a vector apces and $E$ be a subspace of $V$. A basis of $E$ is a family $F = \vectorset{u}$ of vectors in $E$ such that
	
	\begin{enumerate}
		\item $E = \sspan{\v{u_1}, \v{u_2}, ..., \v{u_n}}$
		\item $F = \vectorset{u}$ is linearly independent
	\end{enumerate} 
	
	\begin{examples}
		\item $V = \real^3$ \qquad A basis of $V$ is $\bb{\m{1 \\ 0 \\ 0}, \m{0 \\ 1 \\ 0}, \m{0 \\ 0 \\ 1}}$
		
		\item Let $V$ be any vector space \\
		$E = \bb{\v{0}}$ does not have a basis because the only spanning set if $\bb{\v{0}}$ which is linearly dependent
		
		\begin{lemma}
			Let $E$ be a subspace of $V$ \\
			Let $F_1 = \vectorset{u}$ be a spanning set of $E$ \\
			Let $F_2 = \vectorset{v}$ be a linearly independent subset of $E$ \\
			then $m \ge n$
		\end{lemma}
		
		\begin{proof}
			By contradiction \\
			Assume that $n > m$ \\
			$\bbb{\v{v_1}, \v{v_2}, ..., \v{v_n}} = \bbb{\v{u_1}, \v{u_2}, ..., \v{u_n}} AX$ \\
			$AX = 0$ 
			% A is m x n
			% X is n x 1
		\end{proof}
		
		Fn $j = 1, 2, ..., n$ \\
		$\v{v_j} = \sum_{i=1}^m a_{ij} \v{u_i}$ \qquad (because $F_1$ is a spanning set of $E$) \\
		Let  $A = \pp{a_{ij}}_{1 \le i \le m \\ 1 \le j \le n}$ \\
		% todo line break in subtext
		
		$\sum_{j=1}^m x_j \v{v_j} = \sum_{i=1}^m \pp{\sum_{j=1}^n \alpha_{ij} x_j} \v{u_i} (*)$ \\
		
		$A$ is $m \times n$ and $n > m$ \\
		Therefore, the homogeneous system $AX = 0$ has a non trivial solution. \\
		Using the components of the nontrivial solution in $(*)$, we have $\sum_{j=1}^n x_j \v{v_j} = \v{0}$, but not all $x_j$ are equal to $0$. \\
		ie  $F_2$ is linearly dependent, which is a contradiction
	\end{examples}
	
	\begin{theorem}
		Let $V$ be a vector space and $E$ be a subspace of $V$ such that $E \ne \bb{\v{0}}$ \\
		All basis of $E$ have the same number $k$ of vectors; $k$ is called the dimension of $E$ \\
		Notation \qquad $dim(E) = k$
		
		\begin{proof}
			Let $B_1 = \bb{set u1 to uk}$ and $B_2 = \bb{set v1 to vl}$ be two basis of $E$. We have to prove that $l = k$ \\
			
			\begin{equation*}
			\begin{rcases*}
			B_1 \text{ is a spanning set of } E \\
			B_2 \text{ is linearly independent in } E
			\end{rcases*} \Rightarrow k \ge l
			\end{equation*}
			
			\begin{equation*}
			\begin{rcases*}
			B_2 \text{ is a spanning set of } E \\
			B_1 \text{ is linearly independent in } E
			\end{rcases*} \Rightarrow l \ge k
			\end{equation*}
			
			$k = l$
		\end{proof}
	\end{theorem}
	
	\begin{remark}
		$E = \bb{\v{0}}$ \quad
		$dim(E) = 0$ \quad
		$dim(\real^3) = 3$
	\end{remark}
	
	\begin{examples}
		\item $P_n =$ set of all polynomials of order $\le n$ \\
		We have seen that $B = \bb{1, x, x^2, ..., x^n}$ is a spanning set of $P_n$ and is also linearly independent \\
		
		$B$ is a basis of $P_n$ \\
		therefore $dim(P_n) = n + 1$
		
		\item $M_{2 \times 2} =$ set of all $2 \times 2$ matrices \\
		$E_1 = \mm{1 & 0 \\ 0 & 0}$
		$E_2 = \mm{0 & 0 \\ 1 & 0}$
		$E_1 = \mm{0 & 0 \\ 0 & 1}$
		$E_1 = \mm{0 & 1 \\ 0 & 0}$
		
		$\bb{E_1, E_2, E_3, E_4}$ is a basis of $M_{2 \times 2}$ \\
		$M = \mm{a & c \\ b & d} = aE_1 + bE_2 + dE_3 + cE_4$ \\
		$dim(M_{2 \times 2}) = 2 \times 2 = 4$
	\end{examples}
	
	\section{2018/02/01}
	
	\subsection{Basis \& Dimensions}
	
	\begin{examples}
		\item let $U = \bb{M \in M_{2 \times 2} \mid M = M^T}$ \\
		It is clear that $U$ is a subspace of $M_{2 \times 2}$ \\
		
		\underline{Basis of $U$} \\
		Let $M = \mm{a & c \\ b & d} \quad M^T = \mm{a & b \\ c & d} \quad M = M^T \Leftrightarrow b = c$ \\
		$M \in U \Leftrightarrow M = \mm{a & b \\ b & d}$ \\
		$M = a \mm{1 & 0 \\ 0 & 0} + b \mm{0 & 1 \\ 1 & 0} + d \mm{0 & 0 \\ 0 & 1}$ \\
		% Note above represents _1, A_2, A_3 
		Also $\bb{A_1, A_2, A_3}$ is linearly independent. \\
		$\therefore \bb{A_1, A_2, A_3}$ is a basis of $U$, ie $dim(U) = 3$
	\end{examples}
	
	\begin{lemma} 
		(Fundamental) \\
		If $\bb{\v{u_1}, \v{u_2}, ..., \v{u_n}}$ is a spanning set of $U$ (a subspace of $V$) and $\bb{\v{v_1}, \v{v_2}, ..., \v{v_k}}$ is linearly independent in $U$ then $k \le n$.
	\end{lemma}
	
	\begin{proposition}
		Let $U$ be a subspace of $V$ and $dim(U) = n$
		\begin{enumerate}
			\item Every spanning set of $U$ has \underline{at least} $n$ elements
			\item Every spanning set of $U$ which contains $n$ vectors is a basis of $U$
		\end{enumerate}
	\end{proposition}
	
	\begin{proof}
		\begin{enumerate}
			\item Let $\bb{\vectorseq{u}{n}} = B$ be a basis of $U$ \\
			Let $F = \bb{\vectorseq{v}{m}}$ be a spanning set of $U$ \\
			Note that $B$ is linearly independent, by the fundamental lemma $m \ge n$
			
			\item Let $F = \bb{\vectorseq{v}{n}}$ be a spanning set of $U$ \\
			\underline{Claim} $F$ is also linearly dependent \\
			Suppose otherwise; one of the $\v{v_i}$ is a lc of the other ones. \\
			WLOG $\v{v_n}$ is a lc of $\vv[base=v, end=n-1]$ \\
			$U = \sspan{\vv[base=v, end=n]} = \sspan{\vv[base=v, end=n-1]}$  \\
			Thus, a contradiction as every spanning set must have at least $n$ elements. Therefore, $F$ is linearly independent, and a basis of $U$.
		\end{enumerate}
	\end{proof}
	
	\begin{examples}
		\item T or F: $V = \sspan{x^2, x + 1}$ \\
		False, $dim(P_2) = 3$,  and every spanning set must have at least 3 elements.
		\item T or F: $V = \sspan{\uu{x^2}_{P_1}, \uu{x + 1}_{P_2}, \uu{x^2 - x - 1}_{P_3}, \uu{2x + 3}_{P_4}}$ \\
		% Label as P_1, P_2, P_3, P_4
		Note that $x^2 - x - 1$ is a lc of $x^2$ and $x + 1$ \\
		Let $p(x) = ax^2 + bx + c \in P_2$ \\
		Can we find $x_1, x_2, x_3 \in \real$ st. $p = x_1p_1 + x_2p_2 + x_3p_4$ (*) 
		\begin{eqn}
			\text{(*) implies}
			\begin{cases}
				x_2 + 3x_3 &= c \\
				x_2 + 2x_3 &= b \\
				x_1 &= a
			\end{cases}
		\end{eqn}
		
		$AX = \m{a \\ b \\ c}$
		$X = \m{x_1 \\ x_2 \\ x_3}$ \\
		$A = \m{1 & 0 & 0 \\ 0 & 1 & 2 \\ 0 & 1 & 3}$ \\
		$A$ is invertible, thus \\
		$X = A^{-1} \m{a \\ b \\ c}$ ie $\bb{P_1, P_2, P_4}$ is a spanning set of $P_2$
	\end{examples}
	
	\begin{proposition}
		Let $U$ be a subspace of $V$ and $dim(U) = n$
		
		\begin{enumerate}
			\item Every linearly independent subset of $U$ has \underline{at most} $n$ vectors
			\item Any linearly independent subset of $U$ which contains $n$ elements is a basis of $U$
		\end{enumerate}
		
		\begin{proof}
			\begin{enumerate}
				\item Use the fundamental lemma
				\item Let $B = \bb{\vv[base=u]}$ is a basis of $U$ and $F = \bb{\vv[base=v]}$ a linearly independent set in $U$
				\item \underline{Claim} $F$ is also a spanning set o $U$ \\
				Proof by contradiction \\
				$\v{w}$ is not a lc of $\vv[base=v]$ then $\bb{\vv[base=v], \v{w}}$ is linearly independent \\
				$\vectorseqtwo{\alpha}{v} = \v{0}$ \\
				This is a linearly independent subset with $n + 1$ elements, which is a contradiction
			\end{enumerate}
		\end{proof}
	\end{proposition}
	
	\begin{proposition}
		Let $U$ and $W$ be two subspaces of a vector space $V$
		\begin{enumerate}
			\item If $U \subseteq W$ then $dim(U) \le dim(W)$ 
			\item If $U \subseteq W$ and $dim(U) = dim(W)$ then $U = W$
			\begin{proof}
				\begin{enumerate}
					\item A basis of $U$ is a linearly independent set of vectors in $W$, thus has at most $dim(W)$ vectors
					\item $U \subseteq W \qquad dim(U) = dim(W) = n$ \\
					Let $B = \bb{\vv}$ be a basis of $U$; $B$ is a linearly independent set of vectors in $W$ and $B$ has $n = dim(W)$ vectors. By the previous proposition, $B$ is a basis of $W$. \\
					$\therefore W = \sspan{\vv} = U$
				\end{enumerate}
			\end{proof}
		\end{enumerate}
	\end{proposition}
	
	\begin{examples}
		\item $U = \bb{f \in F(N) \mid f(n + 2) = 3f(n + 1) - 2f(n)}$ \\
		\begin{tabular}{@{} l l}
			$f_1(n) = 1$ & $(1, 1, 1, ...)$ \\
			$f_2(n) = 2^n$ & $(2^0, 2^1, 2^2, ...)$
		\end{tabular}
	\end{examples}
	
	\section{2018/02/06}
	
	\begin{example} 
		$U = \bb{f \in F(\natural) \mid f(n + 2) - 3f(n + 1) + 2 f(n) = 0}$ \\
		Note that $U$ is the set of all sequences $\bb{x_n}_{n \ge 0}$ such that $x_{n + 2} - 3x_{n + 1} + 2x_n = 0$ \\
		Note that if $f(n) = r^n \in U$, then $r = 1$ or $r = 2$ \\
		$f_1(n) = 1 \ \quad \forall n$ is an element of $U$ \\
		$f_2(n) = 2^n \quad \forall n$ \\
		$\bb{f_1, f_2}$ is a basis of $U$ \\
		If $f \in U$ and $f(0) = f(1) = 0$, using the relation $f(n + 2) - 3f(n + 1) + 2f(n) = 0$, we can deduce that $f(n) = 0 \quad \forall n$. \\
		$\bb{f_1, f_2}$ is linearly independent \\
		Suppose that $\alpha f_1 + \beta f_2 = 0$ \\
		% \begin{eqn}
		% 	\begin{cases}
		% 		\alpha f_1(0) + \beta f_2(0) = 0 \\
		% 		\alpha f_1(1) + \beta f_2(1) = 0
		% 	\end{cases}
		
		% 	\Leftrightarrow
		
		
		% \end{eqn}
		
		% \begin{eqn}
		% 	\begin{cases}
		% 		\alpha + \beta = 0 \\
		% 		\alpha + 2 \beta 0
		% 	\end{cases}
		% \end{eqn}
		\todo
		
		$\bb{f_1, f_2}$ is a spanning set of $U$ \\
		Let $f \in U$ \\
		$\exists a, b \in \real$ such that
		
		\begin{eqn}
			\begin{cases}
				a f_1(0) + b f_2(0) = f(0) \\
				a f_1(1) + b f_2(1) = f(1)
			\end{cases}
		\end{eqn}
		
		$\Leftrightarrow$
		
		\begin{eqn}
			\begin{cases}
				a + b = f(0) \\
				a + 2b = f(1)
			\end{cases}
		\end{eqn}
		
		$b = f(1) - f(0)$ \\
		$a = 2 f(0) - f(1)$ \\
		Let $g(n) = f(n) - (2f(0) - f(1)) f_1(n) - (f(1) - f(0)) f_2 (n)$ \\
		$g \in U$ and $g(0) = 0$, $g(1) = 0$ \\
		$\therefore$ using (*) $g(n) = 0 \quad \forall n$ \\
		ie $f(n) = (2f(0) - f(1)) f_1 (n) + (f(0) - f(1)) f_2 (n)$ \\
		
		Any sequence $\bb{x_n}_n$ such that $x_{n + 2} = 3x_{n + 1} + 2x_n = 0$ can be written as
		
		$$x_n = (2x_0 - x_1) + (x_0 - x_1) 2^n$$
		
		
	\end{example}
	
	\begin{block}[Exercises]
		Find a basis for each of the following subspaces
		\begin{enumerate}
			\item $U = \bb{f \in F(\natural) \mid f(n + 2) - 4f(n + 1) + 4f(n) = 0}$
			\item $U = \bb{f \in F(\natural) \mid f(n + 2) - 5f(n + 1) + 6f(n) = 0}$
		\end{enumerate}
	\end{block}
	
	\subsection{Direct Sum}
	
	Let $V$ be a vector space and $E, F$ are 2 subspaces of $V$ \\
	$E + F = \bb{\v{u} = \v{u_1} + \v{u_2}, \v{u_1} \in E, \v{u_2} \in F} \subseteq V$
	
	\begin{examples}
		\item $V = \real^2$ \\
		$E = \sspan{\m{1 \\ 0} = i} \qquad F = \sspan{\m{0 \\ 1} = j}$  \\
		$E + F = \real^2$ 
		
		\item $V = \real^3$ \\
		$E = \sspan{i = \m{1 \\ 0 \\ 0}, j = \m{0 \\ 1 \\ 0}}$ \quad xy-plane \\
		$F = \sspan{j = \m{0 \\ 1 \\ 0}, k = \m{0 \\ 0 \\ 1}}$ \quad yz-plane
	\end{examples}
	
	\begin{definition}
		Let V be a vector space and $E$ and $F$ be 2 subspaces of $V$ \\
		$V$ is said to be the direct sum of $E$ and $F$ \\
		(Notation: = $V = E \oplus F$) \\
		If $V = E + F$ and  $E \cap F = \bb{\v{0}}$
	\end{definition} \\
	
	\begin{proposition}
		If $V = E_1 \oplus E_2$, then every vector $\v{u} \in V$ can be written \underline{uniquely} as $\v{u} = \v{u_1} + \v{u_2}$, where $\v{u_1} \in E_1, \v{u_2}, \in E_2$ \\
		
		\begin{proof}
			\begin{eqn}
				\v{u} &= \v{u_1} + \v{u_2} \qquad && \v{u_1}, \v{v_1} \in E_1 \\
				&= \v{v_1} + \v{v_2} \qquad && \v{u_2} + \v{v_2} = \in E_2 \\
				& \v{u_1} + \v{u_2} &&= \v{v_1} + \v{v_2} \\
				& \v{w} = \uu{\v{u_1} - \v{v_1}}_{\in E_1} &&= \uu{\v{v_2} - \v{u_2}}_{\in E_2} = \v{0}
			\end{eqn}
		\end{proof}
		
		$\v{w} \in E_1, \v{w} \in E_2, \v{w} \in E_1 \cap E_2$ \\
		ie $\v{w} = \v{0}$
	\end{proposition}
	
	\begin{theorem}
		Let $V$ be a finite dimensional vector space \\
		Assume that $V = E_1 \oplus E_2$ \\
		then $dim(V) = dim(E_1) + dim(E_2)$ \\
		More precisely, if $B_1 = \bb{\vv}$ is a basis of $E_1$ and $B_2 = \bb{\vv[base=v, end=m]}$ is a basis of $E_2$, then $B = B_1 \cup B_2$ is a basis of $V$ 
		
		\begin{proof}
			$\because V = E_1 \oplus E_2, V = E_1 + E_2$ \\
			$\therefore B$ is a spanning set of $V$
		\end{proof}
		
		\begin{eqn}
			\v{u} &\in V \\
			\v{u} &= \uu{\v{w_1}}_{\in E_1} + \uu{\v{w_2}}_{\in E_2} \\
			&= \ssum \alpha_1 \v{u_i} + \ssum[sup=m] \beta_i + \v{v_i} 
		\end{eqn}
		$B$ is linearly independent $\pp{\text{bc } E_1 \cap E_2 = \bb{\v{0}}}$
		\begin{eqn}
			\ssum \alpha_i \v{u_i} + \ssum[sup=m] \beta_i \v{v_i} &= \v{0} \Leftrightarrow \\
			\ssum \alpha_i \v{u_i} &= - \ssum[sup=m] \beta_i \v{v_i} = \v{w} \\
			\v{w} \in E_1 \cap E_2 &= \bb{\v{0}} \\
			\v{w} &= \v{0} \\
		\end{eqn}
		
		$$\ssum \alpha_i \v{u_i} = \v{0} \Rightarrow \alpha_i = 0 \quad \forall i = 1, 2, ..., n \quad B_1 \text{ is a basis}$$
		$$\ssum[sup=m] \beta_i \v{v_i} = \v{0} \Rightarrow \beta_i = 0 \quad \forall i = 1, 2, ..., m \quad B_2 \text{ is a basis}$$
		
	\end{theorem}
	
	\begin{examples}
		\item $E = \sspan{2 - x, 1 + x^2}$ \qquad Find $F$ such that \\
		$E \oplus F = P_2$ \\
		$\because \bb{2 - x, 1 + x^2}$ is linearly independent \\
		$\therefore dim(E) = 2$ \\
		if $P_2 = E \oplus F$ \\ 
		$3 = dim(P_2) = dim(E) + dim(F)$ \\
		$dim(F) = 1$ \\\\
		Let $p(x) = 1 \quad \forall x$ \\
		$p \in P_2$, but $p \notin E$ \\
		$F = \sspan{p}$ \\
		$P_2 = F \oplus E$
		
		\item Let $V = M_{2 \times 2}$ \\
		$E = \bb{M \in M_{2 \times 2} \mid M = M^T}$ \\
		Find $F$ such that $E \oplus F = M_{2 \times 2}$ \\
		
		\begin{eqn}
			M_1 = A + A^T \\
			M_1^T = A^T + \pp{A^T}^T = A^T + A = M_1 \\
			M_2 = A - A^T \\
			M_2^T = A^T - A = -M_2 \\
			E = \bb{M \in M_{n \times n} \mid M = M^T} \\
			F = \bb{M \in M_{n \times n} \mid M^T = -M} \\
			M \in E \cap F \Rightarrow M = 0 
		\end{eqn}
		Let $A \in M_{n \times n}$ \\
		$$A = \uu{\frac{1}{2} (A + A^T)}_{\in E} + \uu{\frac{1}{2} (A - A^T)}_{\in F}$$ \\
		$M_{n \times n} = E \oplus F$
	\end{examples}
	
	
	\section{2018/02/08}
	
	\begin{equation}
	S = \bb{M \in M_{n \times n} \mid M^T = M} \\
	A = \bb{M \in M_{n \times n} \mid M^T = -M}
	\begin{cases}
	M_{n \times n} = S \oplus A \\
	dim(A) = \frac{n^2 - n}{2} \\
	dim(S) = \frac{n^2 + n}{2}
	\end{cases}
	\end{equation}
	
	$dim(E \oplus F) = dim(E) + dim(F)$ \\
	If $dim(E + F) = dim(E) + dim(F)$ then it is a direct sum.
	
	\begin{block}[Exercise]
		$dim(E + F) = dim(E) + dim(F) - dim(E \cap F)$ \\
		$(E \cap F)$ is a subspace of $V$ whenever $E$ and $F$ are subspaces of $V$.
	\end{block}
	
	\subsection{Coordinates}
	
	Let $V$ be a vector space such that $dimm(V) = n$ \\
	Let $B = \bb{\vv}$ be a basis of $V$. \\
	Given $\v{w}$ in $V$, $\v{w}$ can be written \underline{uniquely} as a linear combination of vectors in $B$.
	
	ie $\v{w} = \ssum x_i \v{u_i}$ \\
	
	Therefore the column-matrix $\m{x_1 \\ x_2 \\ \vdots \\ x_n}$ uniquely identifies $\v{w}$. \\
	
	$\m{x_1 \\ x_2 \\ \vdots \\ x_n}$ is called the \underline{coordinate-vector} of $\v{w}$ relative to the basis $B$.
	
	\begin{examples}
		\item $M_{2 \times 2} \qquad B = \bb{E_1 = \m{1 & 0 \\ 0 & 0}, E_2 = \m{0 & 0 \\ 1 & 0}, E_3 = \m{0 & 0 \\ 0 & 1}, E_4 = \m{0 & 1 \\ 0 & 0}}$ \\
		$M = \m{1 & 3 \\ 3 & 2}$ \\
		$U = \bb{A \in M_{ \times 2} \mid A^T = A}$ \\
		A basis of $U$ is given by $B_1 = \bb{A_1 = \m{1 & 0 \\ 0 & 0}, A_2 = \m{0 & 1 \\ 1 & 0}, A_3 = \m{0 & 0 \\ 0 & 1}}$ \\\\
		Coordinate vector of $M$ relative to $B$ \\
		$M = E_1 + 3E_2 + 2E_3 + 3E_4 \leftrightarrow \m{1 \\ 3 \\ 2 \\ 3}$ \\\\
		Coordinate vector of $M$ relative to $B_1$ \\
		$M = A_1 + 3A_2 + 2A_3 \leftrightarrow \m{1 \\ 3 \\ 2}$ (Note that the order for which you write the basis is important)
		
		\item Find a basis $B$ of $U = \sspan{\uu{1 + x}_{P_1}, \uu{3 + x^2}_{P_2}, \uu{(x - 1)^2}_{P_3}}$ and find the coordinate vector of $p(x) = (x - 1)^2$ relative to $B$. \\
		$\bb{P_1, P_2, P_3}$ is a spanning of $U$. \\
		Linear Independence \\
		$\alpha_1 P_1 + \alpha_2 P_2 + \alpha_3 P_3 = 0$ \\
		$\uu{A}_{3 \times 3} \m{\alpha_1 \\ \alpha_2 \\ \alpha_3} = \uu{0}_{3 \times 1}$ where $A = \m{1 & 3 & 1 \\ 1 & 0 & -2 \\ 0 & 1 & 1} \rightsquigarrow \m{1 & 0 & -2 \\ 0 & 1 & 1 \\ 0 & 0 & 0}$ \\
		$P_3 = -2 P_1 + P_2$ \\
		$\bb{P_1, P_2}$ is linearly independent \\
		$B = \bb{P_1, P_2}$ is a basis of $U$ and coordinates of $P = P_3$ relative to $B$ is $\m{-2 \\ 1}$ \\
		\begin{remark}
			If $V$ is a n-dimensional vector space over $\real$ \\
			$B = \bb{\vv}$ is a basis of $V$ \\
			The map $T: V \rightarrow \real^n, T(U) = \m{x_1 \\ x_2 \\ \vdots \\ x_n}$ \\
			where $\m{x_1 \\ x_2 \\ \vdots \\ x_n}$ is the coordinate-vector of $\v{u}$ relative to $B$ \\
			is an isomorphism $\v{u} \leftrightarrow \m{x_1 \\ x_2 \\ \vdots \\ x_n}$
		\end{remark}
	\end{examples}
	
	\subsection{Linear Transformations (Mapping)}
	
	\begin{definition}
		Let $V$ and $W$ be two vector spaces over $\real$ \\
		A map (of function) $T: V \rightarrow W$ is called a linear transformation of the following properties hold.
		
		\begin{enumerate}
			\item $T(\v{u_1} + \v{u_2}) = T(\v{u_1}) + T(\v{u_2})$ whenever $\v{u_1}, \v{u_2} \in V$
			
			\item $T(\alpha \v{u}) = \alpha T(\v{u})$ whenever $\v{u} \in V \quad \alpha \in \real$
		\end{enumerate}
		
	\end{definition}
	
	\begin{remark}
		$T : V  \rightarrow W$ is a linear transformation iff $T(\alpha_1 \v{u_1} + \alpha_2 \v{u_2}) = \alpha_1 T(\v{u_1}) + \alpha_2 T(\v{u_2})$ whenever $\v{u_1}, \v{u_2} \in V \quad \alpha_1, \alpha_2 \in \real$ \\
		or equivalently: $T(\ssum \alpha_i \v{u_i}) = \ssum \alpha_i T(\v{u_i})$ \\
		whenever $\alpha_i \quad i = 1, ..., n \in \real \qquad \v{u_i} \quad i = 1, ..., n \in V$
	\end{remark}
	
	\begin{examples}
		\item 
		\begin{eqn}
			V &= P \\
			T: V &\rightarrow R \\
			T(p) &= [p(0)]^2 \\\\
			p_1(x) &= x - 1 \\
			p_2(x) &= x + 1 \\
			T(p_1) &= (p_1(0))^2 = 1 \\
			T(p_2) &= 1 \\
			T(p_1 + p_2) &= 0
		\end{eqn}
		$T$ is not a linear transformation
		\item The coordinate-map $dim(V) = n$ and $B = \bb{\vv}$ is a basis of $V$ \\
		The map $T: V \rightarrow \real^n$ \\
		$T(\v{u}) = \m{x_1 \\ x_2 \\ \cdots \\ x_n} \leftarrow$ coordinates of $\v{u}$ relative to $B$ \\
		$T$ is a linear transformation \\
		\item $T: \real^p \rightarrow \real^q$ \\
		$\uu{T(X)}_{q \times 1} = \uu{A}_{q \times p} \uu{X}_{p \times 1}$, where $A$ is a $q \times p$ matrix, is a linear transformation
		\item $T: P_2 \rightarrow P_2$ \\
		$T(p)(x) = xp'(x) + \int^1_0 p(x)dx$ \\
		$T(p_1 + p_2)(x) = x(p'_1(x) + p'_2(x)) + \int^1_0 (p_1(x) + p_2(x)) dx = xp'_1(x) + \int^1_0 p_1(x)dx + xp'_2(x) + \int^1_0 p_2(x)dx = T(p_1)(x) + T(p_2)(x)$ \\
		$T(\alpha p)(x) = \alpha x p'(x) + \alpha \int^1_0 p(x)dx = \alpha T(p)(x)$
	\end{examples}
	
	\begin{proposition}
		Let $T: V \rightarrow W$ be a linear transformation 
		
		\begin{enumerate}
			\item $T(\v{O_V}) = \v{O_W}$
			\item Let $E$ be a subspace of $V$ \\
			$T(E) = \bb{T(\v{u}), \text{ where } \v{u} \in E}$ is a subspace of $W$
			\item Let $F$ be a subspace of $W$ \\
			$T^{-1} (F) = \bb{\v{u} \in V \mid T(\v{u}) \in F}$ is a subspace of $V$
			
			\begin{proof}
				\begin{enumerate}
					\item 
					\begin{eqn}
						\v{u} &\in V \\
						\v{u} + \v{O_V} &= \v{u} \\
						T(\v{u} + \v{O_V}) &= T(\v{u}) \\
						T(\v{u}) + T(\v{O_V}) &= T(\v{u})
					\end{eqn}
					$\therefore T(\v{O_V}) = \v{O_W}$
					\item Let $E \subseteq V$ be a subspace of $V$ \\
					$T(E) = \bb{T(\v{u}), \text{ where } \v{u} \in E}$ (reverse in) $\v{O_W}$ \\
					$\v{O_V} \in E, \ \therefore \v{O_W} = T(\v{O_V}) \in T(E)$ \\
					Let $\v{w_1}, \v{w_2} \in T(E); \ \alpha_1, \alpha_2 \in \real$ \\
					$\v{w_1} = T(\v{u_1}) \text{ where } \v{u_1} \in E$ \\
					$\v{w_2} = T(\v{u_2}) \text{ where } \v{u_2} \in E$ \\
					$\alpha_1 \v{w_1} + \alpha_2 \v{w_2} = \alpha_1T(\v{u_1}) + \alpha_2 T(\v{u_2}) = T(\alpha_1 \v{u_1} + \alpha_2 \v{u_2}) = T(\v{u})$ \\
					where $\v{u} = \alpha_1 \v{u_1} + \alpha_2 \v{u_2} \in E$ \\
					ie $\alpha_1 \v{w_1} + \alpha_2 \v{w_2} \in T(E)$
					\item 
					\begin{eqn}
						T^{-1} (F) &= \bb{\v{u} \in V \mid T(\v{u}) \in F} \\
						\text{Let } \v{u_1}, \v{u_2} &\in T^{-1}(F) \ \alpha_1, \alpha_2 \in \real \\
						T(\v{u_1}) &\in F, T(\v{u_2}) \in F \\
						\alpha_1 \v{u_1} + \alpha_2 \v{u_2} &\in T^{-1}(F) \\
						T(\alpha_1 \v{u_1} + \alpha_2 \v{u_2}) &= \alpha_1 \uu{T(\v{u_1})}_{\in F} + \alpha_2 \uu{T(\v{u_2})}_{\in F} \in F \\
						\alpha_1 \v{u_1} + \alpha_2 \v{u_2} &\in T^{-1} (F)
					\end{eqn}
					
				\end{enumerate}
				
			\end{proof}
		\end{enumerate}
	\end{proposition}
	
	\section{2018/02/13}
	
	(From someone else's notes)
	
	\subsection{Linear Transformations}
	
	\begin{proposition}
		$T: V \rightarrow W$ is a linear transformation
		\begin{enumerate}
			\item If $E$ is a subspace of $V$ then $T(E) = \bb{T(\v{u}) \text{ where } \v{u} \in E}$ is a subspace of $W$.
			\item If $F$ is a subspace of $W$ then $T^{-1}(F) = \bb{\v{u} \in V \st T(\v{u}) \in F}$ is a subspace of $V$
		\end{enumerate}
	\end{proposition}
	
	\begin{examples}
		\item \begin{eqn}
			T: \real^3 &\rightarrow \real^2 \\
			T \mm{x \\ y \\ z} &= \mm{x \\ z} \\
			&= \uu{\mm{1 & 0 & 0 \\ 0 & 0 & 1}}_{2 \times 3} \uu{\m{x \\ y \\ z}}_{3 \times 1} \\
			&\text{will be a linear transformation because it can be written in this format} \\ 
			& \text{(projection onto xz plane)} \\
			E &= \sspan{\m{1 \\ 0 \\ 0}, \m{0 \\ 1 \\ 0}} \text{ (xy plane)} \\
		\end{eqn}
		if $\v{u} \in E$ then $\v{u} = \m{a \\ b \\ 0}$ and $T(\v{u}) = \m{a \\ 0}$ \\
		$T(E) = \sspan{\m{1 \\ 0}} \rightarrow x $ axis is in $\real^2$
		
		\item Let $F = \sspan{\m{1 \\ 0}}$ \\
		\begin{eqn}
			T^{-1}(F) &= \bb{\v{u} = \mm{x \\ y \\ z} \text{ such that } T(\v{u}) \in F} \\
			T(\v{u}) &= \mm{x \\ z} = t \mm{1 \\ 1} \quad t \in \real \\
			& \quad x = t, z = t, y \text{ is arbitrary } \rightarrow y = s \\
			T^{-1}(F) &= \bb{\v{u} = \mm{t \\ s \\ t} \mid t, s \in \real} \\
			T^{-1}(F) &= \sspan{\m{1 \\ 0 \\ 1}, \m{0 \\ 1 \\ 0}}
		\end{eqn}
		$T^{-1}(F)$ is a subspace, $T^{-1}(F)$ cannot be empty, $\v{0} \in T^{-1}(F)$
		
	\end{examples}
	
	Particular Cases: $Ker(T)$ and $Im(T)$ \\
	Let $T: V \rightarrow W$ be a linear transformation \\
	\begin{enumerate}
		\item $E = V$ is a trivial subspace of $V$ \\
		From previous proposition, $T(V)$ is a subspace of $W$. It is called the \underline{image} of $V$ through $T$, denoted $Im(T)$ 
		
		\item $F = \bb{\v{0_W}}$ is also a trivial subspace of $W$. Using the previous proposition $T^{-1}\pp{\bb{\v{0_W}}}$ is a subspace of $V$ called the \underline{kernel} of $T$, denoted $Ker(T)$. \\
		$Ker(T) = \bb{\v{u} \in V \st T(\v{u}) = \v{0_W}}$
	\end{enumerate}
	
	\begin{remark}
		$T: V \rightarrow W$ and $\bb{\vv, ...}$ is a spanning set of $V$ \\
		then $\bb{T(\v{u_1}), T(\v{u_2}), ..., T(\v{u_n}), ...}$ is a spanning set of $T(V) = Im(T)$
		
		\begin{proof}
			Let $\v{w} \in Im(T) \pp{\equiv T(V)}$, then $\exists \v{u} \in V \st \v{w} = T(\v{u}), \v{u} = \ssum \alpha_i \v{u_i}, \v{w} = T(\v{u}) = T(\ssum \alpha_i \v{u_i}) = \ssum \alpha_i T(\v{u_i})$ (Linear combination of $T(\v{u_i})$)
		\end{proof}
	\end{remark}
	
	\begin{examples}
		\item $T: V = \real^p \rightarrow W = \real^q$ \\
		$T(X) = AX$ \\
		A spanning set of $Im(T)$ is given by $T(\v{u_i})$ where $\v{u_i} = \uu{\m{0 \\ 0 \\ 1 \\ 0 \\ 0}}_{p \times 1} \leftarrow i^{th}$ position \\
		$T(\v{u_i}) = A \v{u_i} = i^{th}$ column of $A$ \\
		$Im(T) = Col(A)$ \\
		$Ker(T) = \bb{x \mid AX = 0} = Null(A)$
		
		\item $T: V = P_2 \rightarrow W = \real$ \\
		$T(p) = \int_0^1 p(x) dx$ \quad is this a linear transformation? \\
		
		$T$ is a linear transformation \\
		$\bb{1, , x^2}$ is a spanning set of $V$ \\
		$p_1(x) = 1, p_2(x) = x, p_3(x) = x^2$ \\
		$T(p_1) = 1, T(p_2) = \frac{1}{2}, T(p_3) = \frac{1}{3} \rightarrow$ fractions came from doing transformations \\
		
		\begin{eqn}
			Im(T) &= \sspan{1, \frac{1}{2}, \frac{1}{3}} \subseteq \real \\
			&= \sspan{1} = \real
		\end{eqn}
		$T$ is onto because the whole $W$ is covered by $Im(T)$ \\
		
		$Ker(T) = \bb{p \in P_2 \mid \int_0^1 p(x) dx = 0}$ \\
		$p(x) = ax^2 + bx + c \quad \int_0^1 p(x) dx \Rightarrow \frac{a}{3} + \frac{b}{2} - c = 0$ \\
		$Ker(T) = \sspan{x - \frac{1}{2}, x^2 - \frac{1}{3}}$ \\
		$\frac{a}{3} + \frac{b}{2} + c = 0 \quad c = -\frac{a}{3} - \frac{b}{2}$ \\
		$p(x) = ax^2 + bx - \frac{a}{3} - \frac{b}{2} = a(x^2 - \frac{1}{3}) + b(x - \frac{1}{2})$
		
		\item $T: V = M_{2 \times 2} \rightarrow W = M_{2 \times 2}$ \\
		$T(\uu{M}_{2 \times 2}) = \uu{A}_{2 \times 2} \uu{M}_{2 \times 2}$ \quad where $A = \mm{1 & 2 \\ 1 & 2}$ \\
		Is this a linear transformation? Yes \\
		(if $M = \m{1 & 0 \\ 0 & 1}, AM = \bbb{t\m{1 \\ 1}, s\m{1 \\ 1}}$) \\
		What is the basis of $M_{2 \times 2}$? \quad $E_1 = \m{1 & 0 \\ 0 & 0}, E_2 = \m{0 & 0 \\ 1 & 0}, E_3 = \m{0 & 0 \\ 0 & 1}, E_4 = \m{0 & 1 \\ 0 & 0}$ \\
		$\bb{E_1, E_2, E_3, E_4}$ is a basis of $M_{2 \times 2}$ \\
		$T(E_1) = \m{1 & 0 \\ 1 & 0}, T(E_2) = \m{2 & 0 \\ 2 & 0}, T(E_3) = \m{0 & 2 \\ 0 & 2}, T(E_4) = \m{0 & 1 \\ 0 & 1}$ \\
		$Im(T) = \sspan{\m{1 & 0 \\ 1 & 0}, \m{0 & 1 \\ 0 & 1}}$ because clearly $T(E_2)$ is twice $T(E_1)$ \& $T(E_3)$ is twice $T(E_4)$ \\
		
		$Ker(T) = \bb{M_{2 \times 2} \mid AM = 0}$ \\
		$M = \bbb{x_1 \mid x_2} \Rightarrow AM = \bbb{Ax_1 \mid Ax_2} = 0$ \\
		$Ax_1 = 0 \quad x_1 = t \bbb{2 \\ -1} t \in \real$ \\
		$Ax_2 = 0 \quad x_2 = s \bbb{2 \\ -1} s \in \real$ \\
		
		$M = \m{t & s \\ -t & -s} \quad t, s \in \real$ \\
		
		$Ker(T) = \sspan{\mm{2 & 0 \\ -1 & 0}, \mm{0 & 2 \\ 0 & -1}}$
		
	\end{examples}
	
	\section{2018/02/15}
	
	\begin{definition}
		(one-to-one and onto linear transformations)
		
		\begin{enumerate}
			\item $T: V \rightarrow W$, is said to be one-to-one (or injective) if, whenever $T(\v{u_1}) = T(\v{u_2})$, we have $\v{u_1} = \v{u_2}$
			\item $T: V \rightarrow W$ is said to be onto (or surjective) if $W = J?m(T)$
		\end{enumerate}
	\end{definition}
	
	\begin{remark}
		$T: V \rightarrow W$ is onto iff there is a spanning set $\bb{\vv, ...}$ of $V$ such that $\bb{T(\v{u_1}), T(\v{u_2}), ..., T(\v{u_n}), ...}$ is a spanning set of $W$
	\end{remark}
	
	\begin{proposition}
		$T: V \rightarrow W$, linear transformation is one-to-one iff $Ker(T) = \bb{\v{0_V}}$
		
		\begin{proof}
			$(\Rightarrow)$ Assume $T$ is one-to-one \\
			Recall $Ker(T) = \bb{\v{u} \in v \mid T(\v{u}) = \v{0_W}}$ \\
			Let $\v{u} \in Ker(T), T(\v{u}) = \v{0_W} = T(\v{0_V})$ \\
			$\because T$ is one-to-one, \quad $\therefore \v{u} = \v{0_V}$ \\
			
			$(\Leftarrow)$ Assume that $Ker(T) = \bb{\v{0_V}}$ \\
			Let us prove that $T$ is one-to-one \\
			Let $\v{u_1}, \v{u_2} \in V$, such that \\
			\begin{eqn}
				T(\v{u_1}) &= T(\v{u_2}) \Rightarrow \\
				T(\v{u_1} - \v{u_2}) &= \v{0_W} \\
				\text{ie } \v{u_1} - \v{u_2} \in Ker(T) &= \bb{\v{0_V}} \\
				\v{u_1} - \v{u_2} &= \v{0_V} \\
				\text{ie } \v{u_1} &= \v{u_2}
			\end{eqn}
			
		\end{proof}
	\end{proposition}
	
	\begin{examples}
		\item $T: P_2 \rightarrow P_3$
		\begin{eqn}
			T(p)(x) &= \int_0^x p(t)dt \\
			Ker(T) &= \bb{p \mid T(p) = 0} &&\\
			T(p)(x) &= 0 && \forall x\\ 
			\frac{d}{dx} (T(p)(x)) &= 0 &&\text{ie } p(x) = 0 \quad \forall x \text{ (By Fundamental theorem of calculus)} \\
			Ker(T) &= \bb{0} && \text{ie } T \text{ is one-to-one}
		\end{eqn}
		$\because T(p)(0) = 0 \quad \forall p \in P_2$ \\
		$\therefore$ the polynomial $f(x) = 1 \quad \forall x$ does not belong to $Im(T)$, ie $Im(T) \ne P_3$
		\begin{block}[Exercise]
			Prove that $Im(T) = \bb{p \in P_3 \mid p(0) = 0}$
		\end{block}
		
		\item $T: \real^n \rightarrow \real^m \\
		T(X) = \uu{A}_{m \times n} X$ \\
		\begin{enumerate}
			\item $T$ is one-to-one iff the homogeneous system $AX = 0$ has a unique solution \\
			ie $Rank(A) = n$
			\item $T$ is onto iff $Col(A) = \real^m$ \\
			ie $Rank(A) = dim(Col(A)) = m$
		\end{enumerate}
		\begin{remark}
			$T : V \rightarrow W$ \\
			Let $\v{w}$ be a fixed vector in $W$ \\
			Solving the equation $T\v{u} = \v{w}$ \\
			The set of all solutions is $T^{-1}(\bb{\v{w}})$ 
			\begin{enumerate}
				\item $T^{-1}(\bb{\v{w}})$ can be empty (No solution) \\
				\item $T^{-1}(\bb{\v{w}})$ can have only one vector if \\
				$\v{w} \in Im(T)$ and $T$ is one-to-one
				item $T^{-1}(\bb{\v{w}})$ has infinitely many vectors when $\v{w} \in Im(T)$ and $Ker(T) \ne \bb{\v{0_V}}$
			\end{enumerate}
		\end{remark}
	\end{examples}
	
	\subsection{Isomorphism}
	
	\begin{definition}
		A linear transformation $T: V \rightarrow W$ is said to be an isomorphism if $T$ is one-to-one and onto
	\end{definition}
	
	\begin{examples}
		\item $T: \real^n \rightarrow \real^n \\
		T(X) = \uu{A}_{n \times n} X$ \\
		$T$ is an isomorphism iff $Rank(A) = n$
		\item $T: M_{n \times m} \rightarrow M_{m \times n} \\
		T(A) = A^T$ \\
		Recall $\uu{A}_{n \times m} \in Ker(T) \Leftrightarrow T(A) = A^T = \uu{0}_{m \times n} \\
		A = (A^T)^T = (\uu{0}_{m \times n})^T = \uu{0}_{m \times n}$ \\
		$T$ is one-to-one \\
		Let $B \in M_{m \times n}$ \\
		$T$ is onto \\
		
		$T$ is an isomorphism
		
		\item The coordinate map \\
		If $V$ is a vector space such that $dim(V) = n$ and $\bb{\vv} = B$ is a basis of $V$ \\
		The map $T: V \rightarrow \real^n$ \\
		$T(\v{u}) = \m{x_1 \\ x_2 \\ \vdots \\ x_n} \leftarrow$ coordinates of $\v{u}$ relative to $B$ \\
		is an isomorphism
	\end{examples}
	
	\begin{proposition}
		Let $T: V \rightarrow W$ be an isomorphism \\The inverse transformation $T^{-1}: W \rightarrow V$ is a linear transformation, and is also an isomorphism
		
		\begin{proof}
			$T \circ T^{-1}(\v{w}) = \v{w} \quad \v{w} \in W$ \\
			$T^{-1} \circ T(\v{v}) = \v{v} \quad \v{v} \in V$ \\
			Let $\v{w_1}, \v{w_2} \in W$, $\alpha_1, \alpha_2 \in \real$ \\
			\begin{eqn}
				T^{-1}(\alpha_1 \v{w_1} + \alpha_2 \v{w_2}) &\stackrel{?}{=} \alpha_1 T^{-1}(\v{w_1}) + \alpha_2 T^{-1}(\v{w_2}) \\
				T(T^{-1}(\alpha_1 \v{w_1} + \alpha_2 \v{w_2})) &= \alpha_1 \v{w_1} + \alpha_2 \v{w_2} \\
				T(\alpha_1 T^{-1}(\v{w_1}) + \alpha_2 T^{-1}(\v{w_2})) &= \alpha_1 T(T^{-1}(\v{w_1})) + \alpha_2 T(T^{-1}(\v{w_2})) \\
				&= \alpha_1 \v{w_1} + \alpha_2 \v{w_2}
			\end{eqn}
			
			$\because T$ is one-to-one \\
			$T^{-1} (\alpha_1 \v{w_1} + \alpha_2 \v{w_2}) = \alpha_1 T^{-1} (\v{w_1}) + \alpha_2 T^{-1}(\v{w_2})$ \\
			$Im(T^{-1}) = V$ \\
			$\because \forall \v{v} \in V$ \\
			$\v{v} = T^{-1}(T(\v{v})) \quad \text{ie } \v{v} \in Im(T^{-1})$ \\
			$\v{w} \in Ker(T^{-1}) \quad T^{-1}(\v{w}) = \v{0_V}$ \\
			$\v{w} = T(T^{-1}(\v{w})) = T(\v{0_V}) = \v{0_W}$ \\
			$Ker(T^{-1}) = \bb{\v{0_W}} \quad T^{-1}$ is one-to-one \\
			$T^{-1}$ is also an isomorphism
			
			\begin{block}[Exercise]
				Let $T: V \rightarrow W$ be an isomorphism and $B = \bb{\vv}$ be a basis of $V$ \\
				Let $\v{w_i} = T(\v{u_i})$ \\
				Prove that $\bb{\v{w_1}, \v{w_2}, ..., \v{w_n}}$ is a basis of $W$ \\
				($\therefore dim(V) = dim(W)$)
			\end{block}
		\end{proof}
	\end{proposition}
	
	\begin{block}[Dimension Theorem]
		(Generalization of the Rank Theorem) \\
		$\real^m \rightarrow \real^n$ \qquad $\uu{A}_{n \times m}$ \\
		$\uu{Real(A)}_{dim(col(A)) = dim(Im(T))} + \uu{dim(Null(A))}_{dim(Ker(T))} = m$
		
		\begin{theorem}
			Let $T: V \real W$ be a linear transformation. \\
			Assume $dim(V)$ is finite \\
			Then $dim(V) = dim(Ker(T)) + dim(Im(T))$
		\end{theorem}
	\end{block}
	
	\section{2018/02/20}
	
	\todo
	
	\section{2018/02/22}
	
	Midterm is on Chapter 4 \& 5, and has 4 questions. Rooms will be announced tomorrow; try to get there 10 min early.
	
	\begin{examples}
		\item
		Given $E, F$ are subspaces of $V$, prove that $E \oplus F \subseteq V$. \\
		
		We already know that $E + F \subseteq V$, so we just need to show that $E \cap F = \bb{\v{0_v}}$  \\
		
		To prove equality, show that $dim(V) = dim(E) + dim(F)$
		
		\item
		If $U$ is a subspace of $V$, $W$ is a subspace of $V$, and $U \cup W$ is a subspace of $V$, prove that $U \subseteq W$ or $W \subseteq U$ \\
		
		If $U \nsubseteq W$ and $W \nsubseteq U$, take $\v{u} \in U$ where $\v{u} \notin W$, and $\v{w} \in W$ where $\v{w} \notin U$, then $\v{u} + \v{w} \notin U \cup W$
		
		\item 
		$T; V \rightarrow W$
		
		\begin{enumerate}
			\item $E$ is a subspace of $V$ \\
			$dim(T(E)) = dim(E) - dim(Ker(T) \cap E)$ \\
			Define $T_1: E \rightarrow T(E)$ \\
			\begin{eqn}
				dim(E) &= \uu{dim(Im(T_1))}_{= dim(T(E))} + \uu{dim(Ker(T_1))}_{= dim(E \cap Ker(T))} \\
				\v{u} \in Ker(T_1) &\Leftrightarrow \v{u} \in E \text{ and } T(\v{u}) = \v{0_w} \\
				&\Leftrightarrow \v{u} \in E \text{ and } \v{u} \in  Ker(T) \\
				Ker(T_1) &= Ker(T) \cap E
			\end{eqn}
		\end{enumerate}
	\end{examples}

	\section{2018/03/13}
	
	\todo
	
	\section{2018/03/15}
	
	\begin{block}[Generalization]
		$$T: V \rightarrow W$$ \\
		\begin{itemize}
			\item $B$ is a basis of $V$, $dim(V) = n$
			\item $S$ is a basis of $W$, $dim(W) = m$
		\end{itemize}
	
	Then there exists a unique $m \times n$ matrix
	
	$\bbb{T}_{B, S}$ such that whenever $u \in V$, $\bbb{T(u)}_S = \bbb{T}_{B, S} \bbb{u}_B$
	\end{block}
	
	\begin{proposition}
		Let $V_1, V_2, V_3$ be 3 vector spaces. $dim(V_i) = n_i$ and $B_i$ is a basis of $V_i \ (i = 1, 2, 3)$
		
		Let $F: V_1 \rightarrow V_2$ and $G: V_2 \rightarrow V_3$ be a linear transformation. \\ 
		$G \circ F: V_1 \rightarrow V_3$ is a linear transformation such that \\
		$\uu{\bbb{G \circ F}_{B_1, B_3}}_{n_3 \times n_1} = \uu{\bbb{G}_{B_2, B_3}}_{n_3 \times n_2} \uu{\bbb{F}_{B_1, B_2}}_{n_2 \times n_1}$
	\end{proposition}

	\pagebreak

	\begin{block}[Application]
		$V_B \xrightarrow{T} V_B \quad \bbb{T}_B$ \\
		$\uparrow Id \quad \quad \quad \downarrow Id$ \\
		$V_S \xrightarrow{T} V_S \quad \bbb{T}_S$
		
		\begin{eqn}
			T &= Id \circ T \circ Id \quad \big|^{B = \bb{\vv}}_{S = \bb{\vv[base=v]}} \\
			\bbb{T}_S &= \bbb{Id}_{B, S} \bbb{T}_B\bbb{Id}_{S, B}
		\end{eqn}
	
		Note that the column of $\bbb{Id}_{B, S}$ is $\bbb{u_i}_S$ \\
		Therefore $\bbb{Id}_{B, S} = P$, the transition matrix from $B$ to $S$. \\
		$\bbb{T}_S = P \bbb{T}_B P^{-1}$
	\end{block}
	
	\subsection{Similar Matrices}
	
	Two $n \times n$ matrices $A, B$ are said to be similar if there exists an invertible matrix $P$, such that $A = PBP^{-1}$
	
	\begin{remark}
		\begin{enumerate}
			\item If $A$ and $B$ are similar, $det(A) = det(B)$
			\item tr(A) = tr(B)
		\end{enumerate}
	\end{remark}

	Discussed and got back midterms
	
	\section{2018/03/20}
	
	\subsection{Inner Product}
	
	\begin{block}[Review: Dot Product]
	$u, v \in \real^n$
	
	$u \cdot v = \ssum u_i v_i$ where $u = \m{u_1 \\ u_2 \\ \vdots \\ u_n} \ v = \m{v_1 \\ v_2 \\ \vdots \\ v_n}$
	
	\begin{block}[Properties]
		\begin{eqn}
			u \cdot v &= v \cdot u \\
			(u_1 + u_2) \cdot v &= u_1 \cdot v + u_2 \cdot v \\
			(\alpha u) \cdot v &= \alpha (u \cdot v) \\ 
			u \cdot u &= \ssum u_i^2 \ge 0
		\end{eqn}
	\end{block}
	
	\end{block}

	\begin{block}[Cauchy-Schwarz Inequality]
		$\abs{u \cdot v} \le \sqrt{u \cdot u} \sqrt{v \cdot v} = \abs{\abs{u}} \abs{\abs{v}}$ \\ 
		If $u \ne 0$ and $v \ne 0$, then $\frac{\abs{u \cdot v}}{\abs{\abs{u}} \abs{\abs{v}}} \le 1$ \quad ie $-1 \le \frac{\abs{u \cdot v}}{\abs{\abs{u}} \abs{\abs{v}}} \le 1$ \\
		$\frac{\abs{u \cdot v}}{\abs{\abs{u}} \abs{\abs{v}}} = cos(\theta)$ where $\theta \in \bbb{0, \pi}$ \\
		$\theta$ is called the angle between $u$ and $v$
	\end{block}
	
	\divider
	
	\begin{block}[Definition (Inner Product)]
		Let $V$ be a vector space. \\
		An inner product on $V$ is a function denoted $\ang{,}: V \times V \rightarrow \real$. \\
		(It associates to any pair $(u, v) \in V \times V$ as a number denoted $\ang{u, v}$)
		
		\begin{block}[Properties]
			\begin{enumerate}
				\item $\ang{u, v} = \ang{v, u}$ \quad (Symmetry)
				\item Whenever $u_1, u_2, c \in V \ \alpha_1 \alpha_2 \in \real$: \\
				$\ang{\alpha_1 u_1 + \alpha_2 u_2, v} = \alpha_1 \ang{u_1, v} + \alpha_2 \ang{u_2, v}$
				\item $\ang{u, u} \ge 0$ and $\ang{u, u} = 0$ iff $u = 0_v$
			\end{enumerate}
		\end{block}
	\end{block}

	\begin{examples}
		\item $V = \real^n$ \\ 
		$\ang{u, v} = u \cdot v = \uu{\m{u}^T}_{1 \times n} \uu{\m{v}}_{n \times 1}$
		\item $V = \real^2$
		$u_1 = \m{x_1 \\ y_1} \ u_2 = \m{x_2 \\ y_2}$ \\
		\begin{eqn}
			\ang{u_1, u_2} &= x_1 x_2 - y_1 y_2 \\ 
			&= \m{x_1 & y_1} \m{x_2 \\ -y_2} \\ 
			&= \m{x_1 & y_1} \uu{\m{1 & 0 \\ 0 & -1}}_A \m{x_2 \\ y_2} \\
			&= \m{u_1}^T A \m{u_2}
		\end{eqn}
	
		\begin{enumerate}
			\item \begin{eqn}
				\ang{u_2, u_1} &= \m{u_2}^T A \m{u_1} \\ 
				\ang{u_2, u_1} &= \uu{\m{u_2}^T A \m{u_1}}_{1 \times 1} \\ 
				&= \pp{\m{u_2}^T A \m{u_1}}^T \\ 
				&= \m{u_1}^T A^T \m{u_2} \quad \mathcomment{(A = A^T)} \\ 
				&= \m{u_1}^T A \m{u_2} \\ 
				&= \ang{u_1, u_2}
			\end{eqn}			
		\item \begin{eqn}
			\ang{\alpha_1 u_1 + \alpha_2 u_2, v} &= \m{\alpha_1 u_1 + \alpha_2 u_2}^T A \m{v} \\ 
			&= \pp{\alpha_1 \m{u_1}^T + \alpha_2 \m{u_2}^T} A \m{v} \\
			&= \alpha_1 \ang{u_1, v} + \alpha_2 \ang{u_2, v}
		\end{eqn}
		\item 
		\begin{eqn}
			\ang{u, u} &= \m{u}^T A \m{u} \\
			&= x^2 - y^2 \quad \mathcomment{\text{if} \m{u} = \m{x \\ y}}
		\end{eqn}
		If $\m{u} = \m{0 \\ 1}$, then $\ang{u, u} = -1 < 0$ \\
		Therefore, $\ang{,}$ is not an inner product on $V = \real^2$
		\end{enumerate}
	
		\item $V = \real^2$ \\
		$\ang{u, v} = \m{u}^T A \m{v}$ where $A = \m{2 & -2 \\ -2 & 6}$ \\
		$u_1 = \m{x_1 \\ y_1} \ u_2 = \m{x_2 \\ y_2}$ \\
		$\ang{u_1, u_2} = 2 x_1 x_2 - 2(x_1 y_2 + x_2 y_1) + 6y_1 y_2$ \\
		
		Since $A = A^T$, $\ang{u, v} = \ang{v, u}$ \\
		It is clear that $\ang{\alpha_1 u_1 + \alpha_2 u_2, v} = \alpha_1 \ang{u_1, v} + \alpha_2 \ang{u_2, v}$
		\begin{eqn}
			\ang{u, u} &= \m{u}^T A \m{u} \quad \mathcomment{\text{if} \m{u} = \m{x \\ y}} \\ 
			\ang{u, u} &= 2x^2 - 4xy + 6y^2 \\ 
			&= 2(x^2 - 2x6) + 6y^2 \\
			&= 2((x - y)^2 - y^2) + 6y^2 \\
			&= 2(x - y)^2 + 4y^2 \ge 0
		\end{eqn}
	
		\begin{equation}
			\text{Moreover,} \ang{u, u} = 0 \Leftrightarrow
			\begin{cases}
			x - y = 0 \\y = 0
			\end{cases}
			\text{ie} \m{u} = \m{0 \\ 0}
		\end{equation}
	\end{examples}

	\subsection{Diagonalization of A}
	(Based on example 3 above for $A = \m{2 & -2 \\ -2 & 6}$)
	\begin{enumerate}
		\item Characteristic Polynomial 
		\begin{eqn}
			P_A &= det(A - \lambda I_2) \\ 
			&= det \m{2 - \lambda & -2 \\ -2 & 6 - \lambda} \\
			&= (\lambda - 2)(\lambda - 6) - 4 \\
			&= \lambda^2 - 8\lambda + 12 - 4 \\
			&= \lambda^2 - 8\lambda + 8
		\end{eqn}
	
		\item Eigenvalues 
		\begin{eqn}
			\lambda_1 &= 4 + 2\sqrt{2} \\
			\lambda_2 &= 4 - 2\sqrt{2} 
		\end{eqn}
	
		\item Eigenvectors \\
		$A - \lambda_1 I_2 = \mm{-2 + 2\sqrt{2} & -2 \\ -2 & 2 + 2\sqrt{2}}$: \quad
		$x_1 = \m{1 \\ -1 + \sqrt{2}}$ is an eigenvector \\
		
		$A - \lambda_2 I_2 = \mm{-2 - 2\sqrt{2} & -2 \\ -2 & 2 - 2\sqrt{2}}$: \quad
		$x_2 = \m{1 \\ -1 - \sqrt{2}}$ is an eigenvector \\
		
		$x_1 \cdot x_2 = 1 + \pp{(-1)^2 - (\sqrt{2})^2}^2 = 0$ 
		
		\item Diagonalization \\
		$A = PDP^{-1} = \m{1 & 1 \\ -1 + \sqrt{2} & -1 - \sqrt{2}} \m{4 - 2\sqrt{2} & 0 \\ 0 & 4 + 2\sqrt{2}} \pp{\frac{1}{-2\sqrt{2}} \m{-1-\sqrt{2} & -1 \\ 1 - \sqrt{2} & 1}}$ \\
	\end{enumerate}
	
\end{document}
